{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-PMrv87FCTs",
    "outputId": "8f8f3e0b-1389-4430-a152-d0a6d6c23c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dalle2-pytorch\n",
      "  Obtaining dependency information for dalle2-pytorch from https://files.pythonhosted.org/packages/9a/db/e6b0d7f1209db8794799d2438ac949bac1b0c4cd59d97a7059f0a0c342f3/dalle2_pytorch-1.15.6-py3-none-any.whl.metadata\n",
      "  Downloading dalle2_pytorch-1.15.6-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting accelerate (from dalle2-pytorch)\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/f7/fc/c55e5a2da345c9a24aa2e1e0f60eb2ca290b6a41be82da03a6d4baec4f99/accelerate-0.25.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: click in /home/gleb/anaconda3/lib/python3.11/site-packages (from dalle2-pytorch) (8.0.4)\n",
      "Collecting open-clip-torch<3.0.0,>=2.0.0 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for open-clip-torch<3.0.0,>=2.0.0 from https://files.pythonhosted.org/packages/7c/7f/952fdffa17b15d0c7c51a730860fcf4f4982528ecc753b190dcd46cc944b/open_clip_torch-2.23.0-py3-none-any.whl.metadata\n",
      "  Downloading open_clip_torch-2.23.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting clip-anytorch>=2.5.2 (from dalle2-pytorch)\n",
      "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting coca-pytorch>=0.0.5 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for coca-pytorch>=0.0.5 from https://files.pythonhosted.org/packages/b3/a3/4809b70ec06f9da9f44510ec07ed0921914c630d410abc2a7b912c770c5c/CoCa_pytorch-0.1.0-py3-none-any.whl.metadata\n",
      "  Downloading CoCa_pytorch-0.1.0-py3-none-any.whl.metadata (747 bytes)\n",
      "Collecting ema-pytorch>=0.0.7 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for ema-pytorch>=0.0.7 from https://files.pythonhosted.org/packages/cc/7d/809494d5e55b6f9f3ff07ac949a954d9e87423a3ffc475a50db94dcbcf3e/ema_pytorch-0.3.1-py3-none-any.whl.metadata\n",
      "  Downloading ema_pytorch-0.3.1-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting einops>=0.7.0 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for einops>=0.7.0 from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting embedding-reader (from dalle2-pytorch)\n",
      "  Obtaining dependency information for embedding-reader from https://files.pythonhosted.org/packages/06/01/3f070943bd1204fea16b18d576e57b67cfd6f9b2208ca3b8e0c1523a976a/embedding_reader-1.5.1-py3-none-any.whl.metadata\n",
      "  Downloading embedding_reader-1.5.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting kornia>=0.5.4 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for kornia>=0.5.4 from https://files.pythonhosted.org/packages/55/da/72cb83aa364ebb4d0109965e20c5d33d7063ccab15332c3fd0acfd5609c9/kornia-0.7.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading kornia-0.7.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in /home/gleb/anaconda3/lib/python3.11/site-packages (from dalle2-pytorch) (1.24.3)\n",
      "Requirement already satisfied: packaging in /home/gleb/anaconda3/lib/python3.11/site-packages (from dalle2-pytorch) (23.1)\n",
      "Requirement already satisfied: pillow in /home/gleb/anaconda3/lib/python3.11/site-packages (from dalle2-pytorch) (9.4.0)\n",
      "Collecting pydantic>=2 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for pydantic>=2 from https://files.pythonhosted.org/packages/0a/2b/64066de1c4cf3d4ed623beeb3bbf3f8d0cc26661f1e7d180ec5eb66b75a5/pydantic-2.5.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-warmup (from dalle2-pytorch)\n",
      "  Downloading pytorch_warmup-0.1.1-py3-none-any.whl (6.6 kB)\n",
      "Collecting resize-right>=0.0.2 (from dalle2-pytorch)\n",
      "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
      "Collecting rotary-embedding-torch (from dalle2-pytorch)\n",
      "  Obtaining dependency information for rotary-embedding-torch from https://files.pythonhosted.org/packages/4b/a2/039415e2c340e0bbcea65beaa3ab23332bab9493d0d73d76f2c5793d2bcc/rotary_embedding_torch-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading rotary_embedding_torch-0.4.0-py3-none-any.whl.metadata (702 bytes)\n",
      "Requirement already satisfied: torch>=1.10 in /home/gleb/anaconda3/lib/python3.11/site-packages (from dalle2-pytorch) (2.1.1)\n",
      "Collecting torchvision (from dalle2-pytorch)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/36/3b/a1d0a681ec3abb1bb8ff92c303ed73c0437050d9ac2b210273dc26f3fd8f/torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
      "  Downloading torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm in /home/gleb/anaconda3/lib/python3.11/site-packages (from dalle2-pytorch) (4.65.0)\n",
      "Collecting vector-quantize-pytorch (from dalle2-pytorch)\n",
      "  Obtaining dependency information for vector-quantize-pytorch from https://files.pythonhosted.org/packages/bb/c0/8c5a68486073101be3287c3f46aea85afcc2eff4a6b77648b95cd8d80b78/vector_quantize_pytorch-1.11.8-py3-none-any.whl.metadata\n",
      "  Downloading vector_quantize_pytorch-1.11.8-py3-none-any.whl.metadata (681 bytes)\n",
      "Collecting x-clip>=0.4.4 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for x-clip>=0.4.4 from https://files.pythonhosted.org/packages/c6/41/44c4b2336824263ebcbfa16e8fd7fd4ca010183aa7587779a405ee5ab2b5/x_clip-0.14.4-py3-none-any.whl.metadata\n",
      "  Downloading x_clip-0.14.4-py3-none-any.whl.metadata (724 bytes)\n",
      "Collecting webdataset>=0.2.5 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for webdataset>=0.2.5 from https://files.pythonhosted.org/packages/b7/0d/c6e7777de9b5fd82e75e8ca059ee5af9079770dd2e5431b986c6b15f8779/webdataset-0.2.83-py3-none-any.whl.metadata\n",
      "  Downloading webdataset-0.2.83-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: fsspec>=2022.1.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from dalle2-pytorch) (2023.4.0)\n",
      "Collecting torchmetrics[image]>=0.8.0 (from dalle2-pytorch)\n",
      "  Obtaining dependency information for torchmetrics[image]>=0.8.0 from https://files.pythonhosted.org/packages/62/17/eedb48177a4679b75b82185492f8ad2b4d010e032fd38160e157b0e22028/torchmetrics-1.2.1-py3-none-any.whl.metadata\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting ftfy (from clip-anytorch>=2.5.2->dalle2-pytorch)\n",
      "  Obtaining dependency information for ftfy from https://files.pythonhosted.org/packages/91/f8/dfa32d06cfcbdb76bc46e0f5d69c537de33f4cedb1a15cd4746ab45a6a26/ftfy-6.1.3-py3-none-any.whl.metadata\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: regex in /home/gleb/anaconda3/lib/python3.11/site-packages (from clip-anytorch>=2.5.2->dalle2-pytorch) (2022.7.9)\n",
      "Collecting beartype (from ema-pytorch>=0.0.7->dalle2-pytorch)\n",
      "  Obtaining dependency information for beartype from https://files.pythonhosted.org/packages/46/8a/a90fe78c73958340ed6b6ab128a10598ad5f0ff57537ad17f6ccd1ad830b/beartype-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading beartype-0.16.4-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: huggingface-hub in /home/gleb/anaconda3/lib/python3.11/site-packages (from open-clip-torch<3.0.0,>=2.0.0->dalle2-pytorch) (0.15.1)\n",
      "Collecting sentencepiece (from open-clip-torch<3.0.0,>=2.0.0->dalle2-pytorch)\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /home/gleb/anaconda3/lib/python3.11/site-packages (from open-clip-torch<3.0.0,>=2.0.0->dalle2-pytorch) (4.23.4)\n",
      "Collecting timm (from open-clip-torch<3.0.0,>=2.0.0->dalle2-pytorch)\n",
      "  Obtaining dependency information for timm from https://files.pythonhosted.org/packages/01/a5/eeb717242343d9ca34e7de554a6c08d96a0cfc7005ece4f847b1753581a6/timm-0.9.12-py3-none-any.whl.metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic>=2->dalle2-pytorch)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic>=2->dalle2-pytorch)\n",
      "  Obtaining dependency information for pydantic-core==2.14.5 from https://files.pythonhosted.org/packages/bf/ed/ee221482b51f368884ea6453f3784eeaeb17f5b737589d39d68a89bffde7/pydantic_core-2.14.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.14.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from pydantic>=2->dalle2-pytorch) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (3.9.0)\n",
      "Requirement already satisfied: sympy in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torch>=1.10->dalle2-pytorch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/gleb/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->dalle2-pytorch) (12.3.101)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics[image]>=0.8.0->dalle2-pytorch)\n",
      "  Obtaining dependency information for lightning-utilities>=0.8.0 from https://files.pythonhosted.org/packages/5e/f4/07b748cb9834848de16aaeb1ae38bc9cfcfe3adc22ee2c8ebbe11db82795/lightning_utilities-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading lightning_utilities-0.10.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]>=0.8.0->dalle2-pytorch)\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: scipy>1.0.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from torchmetrics[image]>=0.8.0->dalle2-pytorch) (1.11.1)\n",
      "Requirement already satisfied: requests in /home/gleb/anaconda3/lib/python3.11/site-packages (from torchvision->dalle2-pytorch) (2.27.0)\n",
      "Collecting braceexpand (from webdataset>=0.2.5->dalle2-pytorch)\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: pyyaml in /home/gleb/anaconda3/lib/python3.11/site-packages (from webdataset>=0.2.5->dalle2-pytorch) (6.0)\n",
      "Requirement already satisfied: psutil in /home/gleb/anaconda3/lib/python3.11/site-packages (from accelerate->dalle2-pytorch) (5.9.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from accelerate->dalle2-pytorch) (0.3.2)\n",
      "Collecting pandas<2,>=1.1.5 (from embedding-reader->dalle2-pytorch)\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow<13,>=6.0.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from embedding-reader->dalle2-pytorch) (11.0.0)\n",
      "Requirement already satisfied: setuptools in /home/gleb/anaconda3/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics[image]>=0.8.0->dalle2-pytorch) (68.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from pandas<2,>=1.1.5->embedding-reader->dalle2-pytorch) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from pandas<2,>=1.1.5->embedding-reader->dalle2-pytorch) (2023.3.post1)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->clip-anytorch>=2.5.2->dalle2-pytorch)\n",
      "  Obtaining dependency information for wcwidth<0.3.0,>=0.2.12 from https://files.pythonhosted.org/packages/31/b1/a59de0ad3aabb17523a39804f4c6df3ae87ead053a4e25362ae03d73d03a/wcwidth-0.2.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10->dalle2-pytorch) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from requests->torchvision->dalle2-pytorch) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gleb/anaconda3/lib/python3.11/site-packages (from requests->torchvision->dalle2-pytorch) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from requests->torchvision->dalle2-pytorch) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gleb/anaconda3/lib/python3.11/site-packages (from requests->torchvision->dalle2-pytorch) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/gleb/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10->dalle2-pytorch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/gleb/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas<2,>=1.1.5->embedding-reader->dalle2-pytorch) (1.16.0)\n",
      "Downloading dalle2_pytorch-1.15.6-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading CoCa_pytorch-0.1.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ema_pytorch-0.3.1-py3-none-any.whl (4.8 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydantic_core-2.14.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading webdataset-0.2.83-py3-none-any.whl (68 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading x_clip-0.14.4-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading embedding_reader-1.5.1-py3-none-any.whl (18 kB)\n",
      "Downloading rotary_embedding_torch-0.4.0-py3-none-any.whl (5.1 kB)\n",
      "Downloading vector_quantize_pytorch-1.11.8-py3-none-any.whl (24 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
      "Downloading beartype-0.16.4-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.1/819.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Installing collected packages: wcwidth, sentencepiece, resize-right, braceexpand, webdataset, pydantic-core, lightning-utilities, ftfy, einops, beartype, annotated-types, pydantic, pandas, embedding-reader, vector-quantize-pytorch, torchvision, torchmetrics, rotary-embedding-torch, pytorch-warmup, kornia, ema-pytorch, coca-pytorch, accelerate, x-clip, torch-fidelity, timm, clip-anytorch, open-clip-torch, dalle2-pytorch\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.25.0 annotated-types-0.6.0 beartype-0.16.4 braceexpand-0.1.7 clip-anytorch-2.5.2 coca-pytorch-0.1.0 dalle2-pytorch-1.15.6 einops-0.7.0 ema-pytorch-0.3.1 embedding-reader-1.5.1 ftfy-6.1.3 kornia-0.7.0 lightning-utilities-0.10.0 open-clip-torch-2.23.0 pandas-1.5.3 pydantic-2.5.2 pydantic-core-2.14.5 pytorch-warmup-0.1.1 resize-right-0.0.2 rotary-embedding-torch-0.4.0 sentencepiece-0.1.99 timm-0.9.12 torch-fidelity-0.3.0 torchmetrics-1.2.1 torchvision-0.16.1 vector-quantize-pytorch-1.11.8 wcwidth-0.2.12 webdataset-0.2.83 x-clip-0.14.4\n"
     ]
    }
   ],
   "source": [
    "!pip install dalle2-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yS3aNUSCZBIf",
    "outputId": "0b70aef8-941e-4dfa-d408-90095ea87b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/f3/4f/0ce34195b63240b6693086496c9bab4ef23999112184399a3e88854c7674/fastapi-0.104.1-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.104.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: kaleido in /home/gleb/anaconda3/lib/python3.11/site-packages (0.2.1)\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m520.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m639.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn\n",
      "  Obtaining dependency information for uvicorn from https://files.pythonhosted.org/packages/7e/17/4b7a76fffa7babf397481040d8aef2725b2b81ae19f1a31b5ca0c17d49e6/uvicorn-0.24.0.post1-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting cohere\n",
      "  Obtaining dependency information for cohere from https://files.pythonhosted.org/packages/bc/13/9bb68d76e87327016382c3432c91bc97c3add43cb8e10bf5605495e2bc0b/cohere-4.37-py3-none-any.whl.metadata\n",
      "  Downloading cohere-4.37-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/3e/d3/309769dad11d5f75b81c7252d9dc849ed440d0921215e759af169054f3b6/openai-1.3.7-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.3.7-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/fb/a9/237dc2db35e6ec0fb7dd63e3d10ebe0377559203bd2a87e12a4adbfc8585/tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting anyio<4.0.0,>=3.7.1 (from fastapi)\n",
      "  Obtaining dependency information for anyio<4.0.0,>=3.7.1 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/gleb/anaconda3/lib/python3.11/site-packages (from fastapi) (2.5.2)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n",
      "  Obtaining dependency information for starlette<0.28.0,>=0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from fastapi)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/24/21/7d397a4b7934ff4028987914ac1044d3b7d52712f30e2ac7a2ae5bc86dd0/typing_extensions-4.8.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: click>=7.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from uvicorn) (8.0.4)\n",
      "Collecting h11>=0.8 (from uvicorn)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from cohere) (3.8.5)\n",
      "Collecting backoff<3.0,>=2.0 (from cohere)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
      "  Obtaining dependency information for fastavro<2.0,>=1.8 from https://files.pythonhosted.org/packages/ba/47/9b0fd7881a0be92e4927033b88eb809ce5a224aafc1ecf4753c371491459/fastavro-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading fastavro-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from cohere) (6.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from cohere) (2.27.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/gleb/anaconda3/lib/python3.11/site-packages (from cohere) (1.26.16)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/a2/65/6940eeb21dcb2953778a6895281c179efd9100463ff08cb6232bb6480da7/httpx-0.25.2-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: sniffio in /home/gleb/anaconda3/lib/python3.11/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/gleb/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/gleb/anaconda3/lib/python3.11/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gleb/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gleb/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gleb/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gleb/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/gleb/anaconda3/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
      "Requirement already satisfied: certifi in /home/gleb/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/gleb/anaconda3/lib/python3.11/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gleb/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/gleb/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.14.5)\n",
      "Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-4.37-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: typing-extensions, python-multipart, h11, fastavro, distro, backoff, anyio, uvicorn, tiktoken, starlette, httpcore, httpx, cohere, openai, fastapi\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 3.5.0\n",
      "    Uninstalling anyio-3.5.0:\n",
      "      Successfully uninstalled anyio-3.5.0\n",
      "Successfully installed anyio-3.7.1 backoff-2.2.1 cohere-4.37 distro-1.8.0 fastapi-0.104.1 fastavro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7 python-multipart-0.0.6 starlette-0.27.0 tiktoken-0.5.2 typing-extensions-4.8.0 uvicorn-0.24.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi kaleido python-multipart uvicorn cohere openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKxJv_3TZzer",
    "outputId": "175958c6-928e-4602-9fb2-2fa1f39e222d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dalle2-laion'...\n",
      "remote: Enumerating objects: 151, done.\u001b[K\n",
      "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 151 (delta 19), reused 7 (delta 7), pack-reused 119\u001b[K\n",
      "Receiving objects: 100% (151/151), 6.57 MiB | 1.35 MiB/s, done.\n",
      "Resolving deltas: 100% (67/67), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/LAION-AI/dalle2-laion.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_dPtNndlaQ5M"
   },
   "outputs": [],
   "source": [
    "from dalle2_pytorch.train_configs import TrainDiffusionPriorConfig, TrainDecoderConfig\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dalle2_pytorch.dalle2_pytorch import resize_image_to, maybe\n",
    "from dalle2_pytorch.tokenizer import tokenizer\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dalle2_pytorch.tokenizer import tokenizer\n",
    "from dalle2_pytorch.dalle2_pytorch import resize_image_to, maybe\n",
    "from dalle2_pytorch.train_configs import TrainDiffusionPriorConfig\n",
    "import torch\n",
    "import glob\n",
    "from dalle2_pytorch.train_configs import TrainDecoderConfig\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6WGI3TWPVd_z"
   },
   "outputs": [],
   "source": [
    "#!cat /usr/local/lib/python3.10/dist-packages/typing_extensions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uwY-IKx0m8cA"
   },
   "outputs": [],
   "source": [
    "#!cp /content/drive/MyDrive/latest.pth /content/weights/latest.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yh2FS9GXyRy7"
   },
   "outputs": [],
   "source": [
    "#!cp /content/drive/MyDrive/best.pth /content/weights1/latest.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(x, y):\n",
    "    mse = np.mean((x - y) ** 2)\n",
    "    return 10 * np.log10(1. / mse)\n",
    "\n",
    "def load_image(path=\"\", size=256):\n",
    "    image = cv2.imread(path)[..., ::-1]\n",
    "    max_size = max(image.shape[:2])\n",
    "    ret = np.zeros((max_size, max_size, 3))\n",
    "    ret[: image.shape[0], : image.shape[1]] = image\n",
    "    ret = cv2.resize(ret, (size, size)).astype(np.float64)\n",
    "    return ret/255.0\n",
    "\n",
    "def step(image, decoder, unet, alpha, alpha_next, time, text_encodings, lowres_cond_img):\n",
    "    time_cond = torch.full((image.shape[0],), time, device=decoder.device, dtype=torch.long)\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "        pred = unet.forward(\n",
    "            image,\n",
    "            time_cond,\n",
    "            image_embed=lowres_cond_img,\n",
    "            text_encodings=text_encodings,\n",
    "            lowres_cond_img=lowres_cond_img,\n",
    "        )\n",
    "\n",
    "    sigma = (1 - alpha).sqrt()\n",
    "    sigma_next = (1 - alpha_next).sqrt()\n",
    "    x_0 = (image - sigma * pred) / alpha.sqrt()\n",
    "    x_0 = decoder.dynamic_threshold(x_0)\n",
    "    pred_noise = (image - x_0 * alpha.sqrt()) / sigma\n",
    "    ret  = x_0 * alpha_next.sqrt() + pred_noise * sigma_next\n",
    "    return ret\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def diffusion(\n",
    "    latent,\n",
    "    decoder,\n",
    "    unet,\n",
    "    text_encodings,\n",
    "    cond_img,\n",
    "    alphas,\n",
    "    time_dur\n",
    "):\n",
    "    if latent is None:\n",
    "        image = torch.randn(shape, device = device)\n",
    "    else:\n",
    "        image = latent.detach().clone()\n",
    "    cond_img = maybe(decoder.normalize_img)(cond_img)\n",
    "\n",
    "    for time, time_next in tqdm(time_dur):\n",
    "        image = step(image, decoder, unet, alphas[time], alphas[time_next], time, text_encodings, cond_img)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def generate(latent, decoder, image, text, start_number=1, mode=\"backward\"):\n",
    "    _, text_encodings = decoder.clip.embed_text(tokenizer.tokenize(text).cuda())\n",
    "    image = resize_image_to(image, decoder.image_sizes[start_number-1], nearest=True)\n",
    "    ii=0\n",
    "    for ( unet, vae, image_size, noise_scheduler, sample_timesteps) in zip(\n",
    "        decoder.unets, decoder.vaes, decoder.image_sizes, decoder.noise_schedulers, decoder.sample_timesteps):\n",
    "        if ii<start_number:\n",
    "            ii += 1\n",
    "            continue\n",
    "        lowres_cond_img = resize_image_to(image,target_image_size=image_size,clamp_range=decoder.input_image_range,nearest=True)\n",
    "        lowres_cond_img = maybe(vae.encode)(lowres_cond_img)\n",
    "\n",
    "        if mode == \"backward\":\n",
    "            times = torch.linspace(0, noise_scheduler.num_timesteps, sample_timesteps + 2)[:-1].int()\n",
    "            time_dur = list(zip(times[1:], times[:-1]))\n",
    "        else:\n",
    "            times = torch.linspace(noise_scheduler.num_timesteps, 0, sample_timesteps + 2)[1:].int()\n",
    "            time_dur = list(zip(times[:-1], times[1:]))\n",
    "        times = times.tolist()\n",
    "        latent = diffusion(\n",
    "            latent=latent,\n",
    "            decoder=decoder,\n",
    "            unet=unet,\n",
    "            text_encodings=text_encodings,\n",
    "            cond_img=lowres_cond_img,\n",
    "            alphas=noise_scheduler.alphas_cumprod,\n",
    "            time_dur=time_dur,\n",
    "        )\n",
    "        if mode == \"forward\":\n",
    "            latent = decoder.unnormalize_img(latent)\n",
    "\n",
    "    return latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_cycle(decoder, text, target_image, cond_image, start_number=1, epoch_num=100):\n",
    "    \n",
    "    tmp, text_encodings = decoder.clip.embed_text(tokenizer.tokenize(text).cuda())\n",
    "    best_image = None\n",
    "    ii=0\n",
    "    for (unet, vae, image_size, noise_scheduler, sample_timesteps) in zip(\n",
    "        decoder.unets, decoder.vaes, decoder.image_sizes, decoder.noise_schedulers, decoder.sample_timesteps):\n",
    "        max_psnr = 0.0\n",
    "        best_image = None\n",
    "        if ii<start_number:\n",
    "            ii += 1\n",
    "            continue\n",
    "        learn_image = torch.tensor(cond_image.data, requires_grad=True)\n",
    "        optimizer = torch.optim.SGD(params=[learn_image], lr=2)\n",
    "        image_size_encoded = vae.get_encoded_fmap_size(image_size)\n",
    "        target_image_normalized = maybe(decoder.normalize_img)(\n",
    "            resize_image_to(\n",
    "                target_image,\n",
    "                target_image_size=image_size_encoded,\n",
    "                clamp_range=decoder.input_image_range,\n",
    "                nearest=True,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        times = torch.linspace(noise_scheduler.num_timesteps, 0, sample_timesteps + 2)[1:].int().tolist()\n",
    "        time_dur = list(zip(times[:-1], times[1:]))\n",
    "        for epoch in tqdm(range(epoch_num)):\n",
    "            image = torch.randn_like(target_image)\n",
    "            for time, time_next in time_dur:\n",
    "                optimizer.zero_grad()\n",
    "                lowres_cond_img = maybe(decoder.normalize_img)(\n",
    "                    resize_image_to(\n",
    "                        learn_image,\n",
    "                        target_image_size=256,\n",
    "                        clamp_range=decoder.input_image_range,\n",
    "                        nearest=True,\n",
    "                    )\n",
    "                )\n",
    "                alphas = noise_scheduler.alphas_cumprod[time_next]\n",
    "                predicted = step(image,decoder,unet,alpha=noise_scheduler.alphas_cumprod[time],alpha_next=alphas, time=time, text_encodings=text_encodings, lowres_cond_img=lowres_cond_img)\n",
    "\n",
    "                loss = torch.nn.functional.mse_loss(predicted, target_image_normalized)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                image = predicted.detach()\n",
    "\n",
    "            psnr = PSNR(decoder.unnormalize_img(image)[0].permute(1, 2, 0).cpu().numpy(),target_image[0].permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "            if psnr > max_psnr:\n",
    "                max_psnr = psnr\n",
    "                best_image = learn_image.clone()\n",
    "\n",
    "            print(f\"Epoch: {epoch} loss: {loss.item():.3f}, psnr: {psnr:.3f}\")\n",
    "  \n",
    "    if best_image:\n",
    "        print(f\"Best PSNR: {best_psnr:.3f}\")\n",
    "        return best_image\n",
    "    else:\n",
    "        return cond_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 1, 'decoder': {'unets': [{'dim': 256, 'cond_dim': 512, 'image_embed_dim': 768, 'text_embed_dim': 768, 'cond_on_text_encodings': False, 'channels': 3, 'dim_mults': [1, 2, 3, 4], 'num_resnet_blocks': 4, 'attn_heads': 8, 'attn_dim_head': 64, 'sparse_attn': True, 'memory_efficient': True, 'self_attn': [False, True, True, True]}, {'dim': 256, 'cond_dim': 512, 'image_embed_dim': 768, 'text_embed_dim': 768, 'cond_on_text_encodings': True, 'init_cross_embed': False, 'channels': 3, 'dim_mults': [1, 2, 3, 4], 'num_resnet_blocks': 4, 'attn_heads': 8, 'attn_dim_head': 64, 'sparse_attn': False, 'memory_efficient': True, 'self_attn': [False, False, False, False]}], 'clip': {'make': 'openai', 'model': 'ViT-L/14'}, 'image_sizes': [64, 256], 'channels': 3, 'timesteps': 1000, 'loss_type': 'l2', 'beta_schedule': ['cosine', 'cosine'], 'learned_variance': False, 'text_cond_drop_prob': 0.0, 'image_cond_drop_prob': 0.0}, 'data': {'webdataset_base_url': 'pipe:aws s3 cp --quiet s3://s-datasets/laion-high-resolution/{}.tar -', 'num_workers': 6, 'batch_size': 5, 'start_shard': 0, 'end_shard': 17535, 'shard_width': 5, 'index_width': 4, 'cond_scale': [3.5, 1.0], 'splits': {'train': 0.75, 'val': 0.15, 'test': 0.1}, 'shuffle_train': False, 'resample_train': True, 'preprocessing': {'RandomResizedCrop': {'size': [256, 256], 'scale': [0.75, 1.0], 'ratio': [1.0, 1.0]}, 'ToTensor': True}}, 'train': {'epochs': 1000, 'lr': 0.00012, 'wd': 0.0, 'max_grad_norm': 0.5, 'save_every_n_samples': 400000, 'n_sample_images': 10, 'cond_scale': [3.5, 1.0], 'device': 'cuda:0', 'epoch_samples': 1600000, 'validation_samples': 60000, 'use_ema': True, 'ema_beta': 0.9999, 'save_all': False, 'save_latest': True, 'save_best': True, 'unet_training_mask': [False, True]}, 'evaluate': {'n_evaluation_samples': 10, 'FID': {'feature': 64}, 'LPIPS': {'net_type': 'vgg', 'reduction': 'mean'}}, 'tracker': {'data_path': '.tracker-upsampling', 'overwrite_data_path': True, 'log': {'log_type': 'wandb', 'wandb_entity': 'veldrovive', 'wandb_project': 'upsampler', 'auto_resume': False, 'verbose': True}, 'load': {'load_from': None, 'only_auto_resume': True, 'file_path': '/fsx/aidan/new/dalle2/dev-dalle2/models/latest.pth'}, 'save': [{'save_to': 'wandb'}, {'save_to': 'local', 'save_latest_to': '/fsx/aidan/new/dalle2/dev-dalle2/models/latest.pth', 'save_best_to': '/fsx/aidan/new/dalle2/dev-dalle2/models/best.pth', 'save_meta_to': '/fsx/aidan/new/dalle2/dev-dalle2/models', 'save_type': 'model'}]}}\n",
      "Decoder is ready\n"
     ]
    }
   ],
   "source": [
    "config = TrainDecoderConfig.from_json_path(\"weights/latest.json\").decoder\n",
    "config.sample_timesteps = 100\n",
    "config.ddim_sampling_eta = 0\n",
    "start_number = 1\n",
    "decoder = config.create()\n",
    "decoder_model_state = torch.load(\"weights/latest1.pth\", map_location=torch.device(\"cuda\"))\n",
    "decoder.load_state_dict(decoder_model_state, strict=False)\n",
    "print(\"Decoder is ready\")\n",
    "decoder = decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in glob.glob(\"test_images/*\"):\n",
    "    base_image = [load_image(path=image_path, size=256)]\n",
    "    scaled_image = [load_image(path=image_path, size=64)]\n",
    "    image_name = image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    cond_image = torch.tensor(scaled_image, dtype=torch.float32).permute(0, 3, 1, 2).cuda()\n",
    "    target_image = torch.tensor(base_image, dtype=torch.float32).permute(0, 3, 1, 2).cuda()\n",
    "    with open(f\"prompts/{image_name}.txt\", \"r\") as file:\n",
    "        text_prompt = [file.read()]\n",
    "    latent = generate(target_image, decoder, cond_image, text_prompt, start_number, mode=\"backward\")\n",
    "    latent = torch.nn.functional.interpolate(latent, size=(64, 64), mode=\"area\")\n",
    "    init_image = torch.nn.functional.interpolate(latent, size=(256, 256), mode=\"area\")\n",
    "    learn_cond_image = learn_cycle(\n",
    "        decoder, text_prompt, target_image, cond_image, start_number\n",
    "    )\n",
    "    pred_image = generate(init_image, decoder, learn_cond_image, text_prompt, start_number, mode=\"forward\")\n",
    "    pred_image = pred_image.permute(0, 2, 3, 1).cpu().numpy()[0]\n",
    "    latent = latent.permute(0, 2, 3, 1).cpu().numpy()[0]\n",
    "    learn_cond_image = learn_cond_image.permute(0, 2, 3, 1).cpu().numpy()[0]\n",
    "    curr_psnr = PSNR(pred_image, base_image[0])\n",
    "    plt.suptitle(f\"RGB-PSNR = {round(curr_psnr, 3)}\")\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(base_image[0])\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title(\"Latent Image\")\n",
    "    plt.imshow(latent)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title(\"Learned Conditional Image\")\n",
    "    plt.imshow(learn_cond_image)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title(\"Result Image\")\n",
    "    plt.imshow(pred_image)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"result/{image_name}.png\")\n",
    "    print(f\"RGB-PSNR is {curr_psnr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
